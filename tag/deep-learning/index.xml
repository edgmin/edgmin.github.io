<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | Edgard Minete</title>
    <link>https://edgmin.github.io/tag/deep-learning/</link>
      <atom:link href="https://edgmin.github.io/tag/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 14 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://edgmin.github.io/media/icon_hua2b1b6d47a67b4a2c33931043b472208_26072_512x512_fill_lanczos_center_3.PNG</url>
      <title>Deep Learning</title>
      <link>https://edgmin.github.io/tag/deep-learning/</link>
    </image>
    
    <item>
      <title>TUBSRobustCheck</title>
      <link>https://edgmin.github.io/project/tubsrobustcheck/</link>
      <pubDate>Thu, 14 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://edgmin.github.io/project/tubsrobustcheck/</guid>
      <description>&lt;p&gt;Autonomous vehicles need to understand the world around them in order to safely navigate in our complex and highly dynamic city environments. Towards that objective, diverse deep learning approaches have been proposed and were rather successful. However, recent studies have shown that neural networks can be easily fooled by careful modification of the input image, raising serious concerns about the real robustness of such systems.&lt;/p&gt;
&lt;p&gt;During the last two years, I have worked as a research assistant under the supervision of &lt;a href=&#34;https://www.tu-braunschweig.de/en/ifn/institute/team/sv/baer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andreas Bär&lt;/a&gt; at the &lt;a href=&#34;https://www.tu-braunschweig.de/en/ifn/institute/dept/sv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Signal Processing and Machine Learning Group&lt;/a&gt; of the &lt;a href=&#34;https://www.tu-braunschweig.de/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Technische Universität Braunschweig&lt;/a&gt;. During this time, I worked on diverse topics around the robustness of neural networks. Today, I am very happy to share one of the main results of my work, the &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TUBSRobustCheck&lt;/a&gt; toolbox! TUBSRobustCheck is a PyTorch-based, architecture-agnostic toolbox developed to enable researchers to assess the robustness of their semantic segmentation neural networks against diverse attacks and corruptions.&lt;/p&gt;
&lt;p&gt;Our proposed toolbox is divided into two blocks: &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck/tree/main/robustness/attacks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;attacks&lt;/a&gt;, which contains various individual and universal adversarial attacks, and &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck/tree/main/robustness/corruptions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;corruptions&lt;/a&gt;, which implements common image corruptions, as first introduced by &lt;a href=&#34;https://arxiv.org/pdf/1903.12261.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hendrycks et al, 2019&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Lets now dive into some capabilities of our toolbox!&lt;/p&gt;
&lt;p&gt;Among others, our toolbox implements the Fast Gradient Sign Method &lt;a href=&#34;https://arxiv.org/abs/1412.6572&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(FGSM)&lt;/a&gt; (and its iterative and momentum variants), Generalizable Data-free Universal Adversarial Perturbations &lt;a href=&#34;https://arxiv.org/abs/1801.08092&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(GD-UAP)&lt;/a&gt;, and the Metzen &lt;a href=&#34;https://arxiv.org/abs/1703.01101&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;single image&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1704.05712&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;universal&lt;/a&gt; attacks. Below, I show examples that were produced with out toolbox using a &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0031320320304143&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SwiftNet&lt;/a&gt; as a semantic segmentation neural network.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An example of a Metzen single image attack&#34; srcset=&#34;
               /project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_0523dcf6ca6708ade5f096558c07bf3c.webp 400w,
               /project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_14629d7d5b989bb5aea0a561bfa1a7fe.webp 760w,
               /project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_0523dcf6ca6708ade5f096558c07bf3c.webp&#34;
               width=&#34;760&#34;
               height=&#34;292&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The top left image shows the original image that a neural network generally receives as input. Without any corruption, a state-of-the-art semantic segmentation neural network will produce a segmentation prediction that resembles the clean prediction on the bottom row left. Note that this prediction is very similar to the actual groundtruth image depicted at the bottom row right.&lt;/p&gt;
&lt;p&gt;By applying some attack to it, in this case the Metzen single static image, an adversarial perturbation is computed (top row right). This adversarial perturbation can be added to the original input image to form an adversarial example (top row middle), which still looks like a clean image to humans. However, by feeding the perturbed image to the semantic segmentation network, we observe that the network predicts a scene with distinct semantics, showing the vulnerability of the semantic segmentation network.&lt;/p&gt;
&lt;p&gt;This attack was purposefully designed to fool the neural network into predicting a static scene. In addition to that, our toolbox also contemplates other tips of attacks, such as the dynamic Metzen:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An example of a Metzen&#34; srcset=&#34;
               /project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_5cf68257f3c57e29c626bb60a4f3cc72.webp 400w,
               /project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_e98ad65aba75aa4226a7e8a82f8c9dc6.webp 760w,
               /project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_5cf68257f3c57e29c626bb60a4f3cc72.webp&#34;
               width=&#34;760&#34;
               height=&#34;294&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In this case, instead of fooling the network to produce a some pre-defined (static) image, we fool it into misclassifying some target semantic class of the input image. In this case, we produced a targeted adversarial perturbation to fool the neural network into wrongly classifying pixels of pedestrians. (Stop for a moment and imagine how dangerous would be to have such a system failing/being attacked in this way!)&lt;/p&gt;
&lt;p&gt;I hope this project presentation could show you the importance of investigating the robustness of semantic segmentation neural networks. Please ping me a message in case one any doubts and have a good experience using our &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TUBSRobustCheck&lt;/a&gt; toolbox!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
