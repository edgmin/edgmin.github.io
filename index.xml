<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Edgard Minete</title>
    <link>https://edgmin.github.io/</link>
      <atom:link href="https://edgmin.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Edgard Minete</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 17 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://edgmin.github.io/media/icon_hua2b1b6d47a67b4a2c33931043b472208_26072_512x512_fill_lanczos_center_3.PNG</url>
      <title>Edgard Minete</title>
      <link>https://edgmin.github.io/</link>
    </image>
    
    <item>
      <title>Deep Domain Adaptation - Taxonomy and New Methods</title>
      <link>https://edgmin.github.io/post/masters/</link>
      <pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://edgmin.github.io/post/masters/</guid>
      <description>&lt;p&gt;In this post, I would like to talk a bit about the work I developed under the supervision of &lt;a href=&#34;https://vision.in.tum.de/members/golkov&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Vladimir Golkov&lt;/a&gt; during my master&amp;rsquo;s thesis at the &lt;a href=&#34;https://cvai.in.tum.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Computer Vision &amp;amp; Artificial Intelligence Group&lt;/a&gt; of the Technical University of Munich.&lt;/p&gt;
&lt;p&gt;To begin with, I believe it is worth explaining how I ended up writing my master&amp;rsquo;s thesis at TU Munich, since I was pursuing my studies at TU Braunschweig.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;What lies ahead? Image credit: &amp;lt;a href=&amp;#34;https://unsplash.com/photos/K2u71wv2eI4&amp;#34; target=&amp;#34;_blank&amp;#34; rel=&amp;#34;noopener&amp;#34;&amp;gt;&amp;lt;strong&amp;gt;Unsplash&amp;lt;/strong&amp;gt;&amp;lt;/a&amp;gt;&#34; srcset=&#34;
               /post/masters/back_head_hucdb173c52266abd73a3e5f72ca9b44e7_2187159_9d956ce347f2f7d15cb49bc1b3016bcb.webp 400w,
               /post/masters/back_head_hucdb173c52266abd73a3e5f72ca9b44e7_2187159_fc884cad260072c9e773c1e655e18037.webp 760w,
               /post/masters/back_head_hucdb173c52266abd73a3e5f72ca9b44e7_2187159_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/post/masters/back_head_hucdb173c52266abd73a3e5f72ca9b44e7_2187159_9d956ce347f2f7d15cb49bc1b3016bcb.webp&#34;
               width=&#34;760&#34;
               height=&#34;507&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;When I was planning/looking for a master&amp;rsquo;s thesis topic, I could not really find anything that got my attention at TU Braunschweig. Then, I decided to look around and, after a few days and emails, I was fortunate to get to know Dr. Golkov from TU Munich. As I planned to learn the behind the scenes of deep learning, before accepting to write my master&amp;rsquo;s thesis at TU Munich I asked Vladimir about the potential topics I could work on. He offered me a range of topics, but one of them really stood out in the crowd: understanding deep learning. That was instantly a match for me, as I was definitely searching for something to comprehensively understand deep learning and its concepts.&lt;/p&gt;
&lt;p&gt;After a year reading hundreds of papers, having tons of fruitful discussions, and constantly coding, I successfully presented my master&amp;rsquo;s thesis at TU Braunschweig. Though still an ongoing work, below I present a draft of it with some discussion for those who might be interested. An article on arXiv will also appear soon ðŸ˜„.&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;&lt;/h3&gt;
&lt;h3 id=&#34;heading-1&#34;&gt;&lt;/h3&gt;
&lt;h3 id=&#34;heading-2&#34;&gt;&lt;/h3&gt;
&lt;h3 id=&#34;heading-3&#34;&gt;&lt;/h3&gt;
&lt;h3 id=&#34;heading-4&#34;&gt;&lt;/h3&gt;
&lt;h3 id=&#34;heading-5&#34;&gt;&lt;/h3&gt;
&lt;h2 id=&#34;data-efficiency-in-deep-learning&#34;&gt;Data-efficiency in Deep Learning&lt;/h2&gt;
&lt;p&gt;Deep learning-based methods rely on many strategies to achieve data-efficiency. One of the most common techniques is to endow models with prior knowledge about the underlying problem by using neural network layers with purposefully tailored properties. This approach lies at the heart of deep learning, but is quite often overlooked by machine learning practitioners.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at the prominent example of convolutional neural networks (CNNs).&lt;/p&gt;
&lt;p&gt;CNNs are empowered with convolutional and pooling layers, which leverage them with translation equivariance and scale separation capabilities (not to mention the deep natural image initialization prior - but that&amp;rsquo;s worth another post).&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Convolutional neural network. Image credit: &amp;lt;a href=&amp;#34;https://medium.com/swlh/an-overview-on-convolutional-neural-networks-ea48e76fb186&amp;#34; target=&amp;#34;_blank&amp;#34; rel=&amp;#34;noopener&amp;#34;&amp;gt;&amp;lt;strong&amp;gt;Medium&amp;lt;/strong&amp;gt;&amp;lt;/a&amp;gt;&#34; srcset=&#34;
               /post/masters/cnns_huf86549c46500d4eb201f0cae6f4fca78_56387_852426294e0e4b7ec21258493b8b5cd7.webp 400w,
               /post/masters/cnns_huf86549c46500d4eb201f0cae6f4fca78_56387_1e5cd0c0577948f3f8379d23fbfb7007.webp 760w,
               /post/masters/cnns_huf86549c46500d4eb201f0cae6f4fca78_56387_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/post/masters/cnns_huf86549c46500d4eb201f0cae6f4fca78_56387_852426294e0e4b7ec21258493b8b5cd7.webp&#34;
               width=&#34;760&#34;
               height=&#34;253&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;These aspects of CNNs are essentially what make them shine, as they substantially reduce the number of parameters, the associated computational cost, and the amount of data needed for training. Interestingly (and perhaps unnoticed by many), at a more macroscopic level, certain architectural design and training strategies are also known to greatly benefit neural networks&amp;rsquo; performance. These strategies can be very diverse and range from a simple cluster assumption to more complex concepts such as adversarial learning. However, there is one interesting difference. Namely, there is evidence that the latter strategies pose a more abstract power, being transferable across different data types and tasks. The problem is that there are neither guidelines about when using such strategies is beneficial, nor clear explanations about how they help to solve issues in deep learning approaches.&lt;/p&gt;
&lt;h2 id=&#34;deep-domain-adaptation-taxonomy-and-new-methods&#34;&gt;Deep Domain Adaptation: Taxonomy and New Methods&lt;/h2&gt;
&lt;p&gt;In my master&amp;rsquo;s thesis, I researched about design strategies (patterns) and tried to understand the context in which they are employed and what problems they try to solve. In other words, I investigated task- and data-agnostic architectural design patterns for recurring problems in deep learning.&lt;/p&gt;
&lt;p&gt;For the analysis, I used an existing &amp;ldquo;visual language&amp;rdquo; of the &lt;a href=&#34;https://cvai.in.tum.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Computer Vision &amp;amp; Artificial Intelligence Group&lt;/a&gt;. The idea behind this visual language is to abstract out neural networks&amp;rsquo; topological details, such as type and number of layers, and therefore to provide a common language to analyze deep learning methods. By bringing diverse methods under the same umbrella, I could identify more than 20 design patterns employed throughout deep learning. Furthermore, to understand the machine learning scenario in which each design pattern is commonly employed, I proposed an ontology of machine learning tasks. Combining the list of design patterns and the ontology of machine learning tasks, a methodology for a more structured design of novel deep learning approaches was possible.&lt;/p&gt;
&lt;p&gt;As a proof of concept of the proposed methodology, I extended an existing unsupervised (self-supervised contrastive) deep domain adaptation approach by injecting design patterns into it. Interestingly, the changes leveraged state-of-the-art performance on the popular and challenging &lt;a href=&#34;https://arxiv.org/abs/1710.06924&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VisDA-2017&lt;/a&gt; domain adaptation benchmark, providing empirical evidence that design patterns are interchangeable across distinct machine learning tasks and data types.&lt;/p&gt;
&lt;p&gt;For now, I am still working on this topic and doing additional experiments. Nonetheless, I am confident that the proposed methodology will be the starting point of a more structured analysis of deep learning approaches, and that it will provide guidelines for the design of novel deep learning approaches.&lt;/p&gt;
&lt;p&gt;A paper about it is expected to be released soon. So, be tuned!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Multidisciplinary Journey</title>
      <link>https://edgmin.github.io/post/journey/</link>
      <pubDate>Thu, 14 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://edgmin.github.io/post/journey/</guid>
      <description>&lt;p&gt;As this is the first post of my personal blog, it couldn&amp;rsquo;t be different: today I will write a bit about my academic and professional journey!&lt;/p&gt;
&lt;p&gt;I began my studies back in 2009, when I started a technical course in mechanics at the &lt;a href=&#34;https://www.ifes.edu.br/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Federal Institute of EspÃ­rito Santo&lt;/a&gt;, Brazil. In this course, I was exposed to a range of topics including mechanical projects, electronics, mechanical fabrication, metrology, materials science and beyond. The course was half-half theory and practice. Thereby, I also acquired some hands-on experience. Further, I had the opportunity to lead the welding lab practices for a cohort of about 20 students during one semester.&lt;/p&gt;
&lt;p&gt;In 2010, I was fortunate to be admitted to the main university of my state, &lt;a href=&#34;https://internacional.ufes.br/en/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UFES&lt;/a&gt;, in the undergraduate course of Mechanical Engineering. Simultaneously, I started to learn the English and German languages, as I was planning to one day study abroad.&lt;/p&gt;
&lt;p&gt;In 2011, the Brazilian government launched the &lt;a href=&#34;https://www.gov.br/cnpq/pt-br/acesso-a-informacao/acoes-e-programas/programas/ciencia-sem-fronteiras&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Science Without Boarders - CSF&lt;/a&gt; exchange program, which gave the opportunity to outstanding students to have experiences abroad by providing them with scholarships. As I was already learning foreign languages and had good grades in my undergraduate studies, I could meet the admission requirements and I was offered a scholarship to study in Germany.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;One of the first days in Germany at a shopping mall in Dresden&amp;lt;a href=&amp;#34;&amp;#34;&amp;gt;_&amp;lt;/a&amp;gt;&#34; srcset=&#34;
               /post/journey/dresden_hu8f0d9c0aed59f71f5cceaa03971b1c06_142503_bbe959a4a3da3b4fedda9adcd5e50f1a.webp 400w,
               /post/journey/dresden_hu8f0d9c0aed59f71f5cceaa03971b1c06_142503_f225b98e6cf54094751abf4fc9bae72b.webp 760w,
               /post/journey/dresden_hu8f0d9c0aed59f71f5cceaa03971b1c06_142503_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/post/journey/dresden_hu8f0d9c0aed59f71f5cceaa03971b1c06_142503_bbe959a4a3da3b4fedda9adcd5e50f1a.webp&#34;
               width=&#34;683&#34;
               height=&#34;554&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In 2013, I moved to Dresden, Germany, to then start my exchange program. There, I lived for 3 months and participated in intensive German culture and language courses. After this adaptation period, I moved to the city of Zwickau, where I participated in the Automotive Engineering and Management course as an exchange master student. During the course, I had the opportunity to gain general knowledge about the automotive industry, such as motor development, acoustics, logistics and beyond. Importantly, I also had my first experiences with simulation sciences (in particular computational fluid dynamics), which rapidly increased my interest in the field. Besides that, I did an internship at Audi AG (2014-2015) on the resistance welding development team. There, I learned more about the German labor market, vividly experienced the German culture, and gained knowledge of robotic welding.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;First day of my internship at Audi AG &amp;lt;a href=&amp;#34;_&amp;#34;&amp;gt;_&amp;lt;/a&amp;gt;&#34; srcset=&#34;
               /post/journey/audi_hu312d9d3611ca038e3e6b1e8d68452614_465391_1233293a76424c3ef17275a78d482911.webp 400w,
               /post/journey/audi_hu312d9d3611ca038e3e6b1e8d68452614_465391_41be8ce20fd362f620f5e3d0a6e21aff.webp 760w,
               /post/journey/audi_hu312d9d3611ca038e3e6b1e8d68452614_465391_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/post/journey/audi_hu312d9d3611ca038e3e6b1e8d68452614_465391_1233293a76424c3ef17275a78d482911.webp&#34;
               width=&#34;760&#34;
               height=&#34;549&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;After the internship at Audi AG, I moved back to Brazil to finish my undergraduate studies in Mechanical Engineering. Simultaneously, I did an internship in a local company (Tecvix), where I was responsible for performing mechanical and fluid dynamics simulations for diverse projects in the oil and gas industry. These simulation experiences, together with the similar experiences I had in Germany, directly influenced my decision to further expand my knowledge in the direction of computational sciences.&lt;/p&gt;
&lt;p&gt;After concluding the undergraduate course in Mechanical Engineering in the middle of 2017, I was fortunate to be admitted to the master in &lt;a href=&#34;https://www.tu-braunschweig.de/en/cse&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Computational Sciences in Engineering&lt;/a&gt; at the &lt;a href=&#34;https://www.tu-braunschweig.de/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Technical University of Braunschweig&lt;/a&gt;. During my masters&amp;rsquo; studies, I chose the specialization in Mathematics and Computer Science, but I also took diverse lectures in fluid dynamics. Simultaneously with the theoretical lectures, I sought to improve my research abilities. Therefore, I worked as a research assistant in two different research institutes for more than 2 years.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Undergraduate cerimony &amp;lt;a href=&amp;#34;_&amp;#34;&amp;gt;_&amp;lt;/a&amp;gt;&#34; srcset=&#34;
               /post/journey/bachelors_hu4074748c5bc79a349df7588655202481_115755_703a5dfa9223206c82eca8d58cb02bfa.webp 400w,
               /post/journey/bachelors_hu4074748c5bc79a349df7588655202481_115755_8eda8f211ceec2ae3f29db7c3c97691d.webp 760w,
               /post/journey/bachelors_hu4074748c5bc79a349df7588655202481_115755_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/post/journey/bachelors_hu4074748c5bc79a349df7588655202481_115755_703a5dfa9223206c82eca8d58cb02bfa.webp&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;At the &lt;a href=&#34;https://www.tu-braunschweig.de/en/ifn/institute/dept/sv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institute for Communications Technology&lt;/a&gt;, I worked on projects related to the robustness of semantic segmentation deep neural networks (DNNs) under the supervision of &lt;a href=&#34;https://www.tu-braunschweig.de/en/ifn/institute/team/sv/baer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andreas BÃ¤r&lt;/a&gt;. Among others, the tasks I contributed include: improving an existing approach for domain mismatch estimation by means of multi-task learning and autoencoders; implementing a teacher-student framework for semantic segmentation; and implementing a PyTorch-based &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;toolbox&lt;/a&gt; to assess the robustness of semantic segmentation DNNs against diverse adversarial attacks and corruptions.&lt;/p&gt;
&lt;p&gt;At the same time, I also worked as a research assistant at the &lt;a href=&#34;https://www.tu-braunschweig.de/en/fmb/institute-fk4/institutes/institute-of-joining-and-welding&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institute of Joining and Welding&lt;/a&gt;. There, I had further hands-on experience in simulation sciences and machine learning by working on diverse weld-related projects. My activities there included: development of a differential geometry-based tool to assess porosity properties in welded specimens using 3D computed tomography data; implementation of a ResNet-based data-efficient neural network for the prediction of stress-strain curve of welded alloys using multi-fidelity (2D/3D simulation and experimental) depth-indentation testing data; execution of multi-focal laser welding thermal simulations for welding parameter estimation; and developed a weld bead image segmentation tool to automatically segment and measure weld beads.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An excursion day during my master&amp;amp;rsquo;s studies &amp;lt;a href=&amp;#34;_&amp;#34;&amp;gt;_&amp;lt;/a&amp;gt;&#34; srcset=&#34;
               /post/journey/cse_hu266863908cf2fd53416034f90ff76061_939747_d4c3259c23bbd95c2da16a444a9ab802.webp 400w,
               /post/journey/cse_hu266863908cf2fd53416034f90ff76061_939747_6086d769280749c94ea0a25e16eb640d.webp 760w,
               /post/journey/cse_hu266863908cf2fd53416034f90ff76061_939747_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/post/journey/cse_hu266863908cf2fd53416034f90ff76061_939747_d4c3259c23bbd95c2da16a444a9ab802.webp&#34;
               width=&#34;760&#34;
               height=&#34;459&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;To conclude, in 2020 I wrote my masters thesis at the Technical University of Munich where I was supervised by &lt;a href=&#34;https://vision.in.tum.de/members/golkov&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vladimir Golkov&lt;/a&gt; and worked on topics around understanding of deep learning, self-supervised learning, and unsupervised deep domain adaptation. If you are interested in reading more about my master&amp;rsquo;s thesis, please take a look at &lt;a href=&#34;https://edgmin.github.io/post/masters/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TUBSRobustCheck - assessing the robustness of semantic segmentation neural networks</title>
      <link>https://edgmin.github.io/project/tubsrobustcheck/</link>
      <pubDate>Wed, 13 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://edgmin.github.io/project/tubsrobustcheck/</guid>
      <description>&lt;p&gt;Autonomous vehicles need to understand the world around them in order to safely navigate in our complex and highly dynamic city environments. Towards that objective, diverse deep learning approaches have been rather successful. However, recent studies have shown that neural networks can be easily fooled by careful modification of the input image, raising serious concerns about the real robustness of such systems.&lt;/p&gt;
&lt;p&gt;During the last two years, I have worked as a research assistant under the supervision of &lt;a href=&#34;https://www.tu-braunschweig.de/en/ifn/institute/team/sv/baer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andreas BÃ¤r&lt;/a&gt; at the &lt;a href=&#34;https://www.tu-braunschweig.de/en/ifn/institute/dept/sv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Signal Processing and Machine Learning Group&lt;/a&gt; of the &lt;a href=&#34;https://www.tu-braunschweig.de/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Technische UniversitÃ¤t Braunschweig&lt;/a&gt;. During this time, I worked on diverse topics around the robustness of neural networks. Today, I am very happy to share one of the main results of my work, the &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TUBSRobustCheck&lt;/a&gt; toolbox! TUBSRobustCheck is a PyTorch-based, architecture-agnostic toolbox developed to enable researchers to assess the robustness of their semantic segmentation neural networks against diverse attacks and corruptions.&lt;/p&gt;
&lt;p&gt;Our proposed toolbox is divided into two blocks: &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck/tree/main/robustness/attacks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;attacks&lt;/a&gt;, which contains various individual and universal adversarial attacks, and &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck/tree/main/robustness/corruptions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;corruptions&lt;/a&gt;, which implements common image corruptions, as first introduced by &lt;a href=&#34;https://arxiv.org/pdf/1903.12261.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hendrycks et al, 2019&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Lets now dive deep into some capabilities of the TUBSRobustCheck toolbox!&lt;/p&gt;
&lt;h2 id=&#34;the-tubsrobustcheck-attack-toolbox&#34;&gt;The TUBSRobustCheck Attack toolbox&lt;/h2&gt;
&lt;p&gt;Among others, the proposed toolbox implements the Fast Gradient Sign Method &lt;a href=&#34;https://arxiv.org/abs/1412.6572&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(FGSM)&lt;/a&gt; (and its iterative and momentum variants), Generalizable Data-free Universal Adversarial Perturbations &lt;a href=&#34;https://arxiv.org/abs/1801.08092&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(GD-UAP)&lt;/a&gt;, and the Metzen &lt;a href=&#34;https://arxiv.org/abs/1703.01101&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;single image&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1704.05712&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;universal&lt;/a&gt; attacks. Below, I show examples that were produced with our toolbox using a &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0031320320304143&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SwiftNet&lt;/a&gt; as a semantic segmentation neural network.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An example of a Metzen single image attack&#34; srcset=&#34;
               /project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_0523dcf6ca6708ade5f096558c07bf3c.webp 400w,
               /project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_14629d7d5b989bb5aea0a561bfa1a7fe.webp 760w,
               /project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/project/tubsrobustcheck/Static_normal_hu7a98acbffe7c3279659bad56a75b93ab_423469_0523dcf6ca6708ade5f096558c07bf3c.webp&#34;
               width=&#34;760&#34;
               height=&#34;292&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The top left image shows the original image that a neural network generally receives as input. Without any corruption, a state-of-the-art semantic segmentation neural network will produce a segmentation prediction that resembles the clean prediction at the bottom row left. Note that this prediction is very similar to the actual groundtruth image depicted at the bottom row right.&lt;/p&gt;
&lt;p&gt;By applying some attack to it, in this case the Metzen single static image, an adversarial perturbation is computed (top row right). This adversarial perturbation can be added to the original input image to form an adversarial example (top row middle), which still looks like a clean image to humans. However, by feeding the perturbed image to the semantic segmentation network, we observe that the network predicts a scene with distinct semantics, showing the vulnerability of the semantic segmentation network.&lt;/p&gt;
&lt;p&gt;This attack was purposefully designed to fool the neural network into predicting a static scene. In addition to that, our toolbox also contemplates other types of attacks, such as the dynamic Metzen:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An example of a Metzen dynamic attack&#34; srcset=&#34;
               /project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_5cf68257f3c57e29c626bb60a4f3cc72.webp 400w,
               /project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_e98ad65aba75aa4226a7e8a82f8c9dc6.webp 760w,
               /project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/project/tubsrobustcheck/Dynamic_normal_hu94a5d5213474cf1b2b68882e2c646ae6_403630_5cf68257f3c57e29c626bb60a4f3cc72.webp&#34;
               width=&#34;760&#34;
               height=&#34;294&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In this case, instead of fooling the network to produce some pre-defined (static) image, we fool it into misclassifying some target semantic class of the input image. In this case, we produced a targeted adversarial perturbation to fool the neural network into wrongly classifying pixels of pedestrians. (Stop here for a moment and imagine how dangerous it would be to have a system failing/being attacked in this way!)&lt;/p&gt;
&lt;h2 id=&#34;the-tubsrobustcheck-corruption-toolbox&#34;&gt;The TUBSRobustCheck Corruption toolbox&lt;/h2&gt;
&lt;p&gt;Apart from adversarial attacks, our toolbox also implements diverse corruptions. For that, we followed the work of &lt;a href=&#34;https://arxiv.org/pdf/1903.12261.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hendrycks et al, 2019&lt;/a&gt; and implemented corruptions of four classes: Noise (Gaussian, shot, impulse, and speckle), Blur (defocus, glass, motion, zoom, and Gaussian), Weather (snow, Frost, fog, brightness, and spatter), and Digital (contrast, elastic transform, pixelate, JPEG compression, and saturate). With these classes, we hope to cover some of the most common types of image corruption.&lt;/p&gt;
&lt;p&gt;To illustrate the capabilities of our corruption toolbox, below we have some examples:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Diverse examples of corruptions&#34; srcset=&#34;
               /project/tubsrobustcheck/corruptions_hu35adbfae16189e3e7129a7ebe2250739_527923_869b30c362c544b6b1e78139973c81b1.webp 400w,
               /project/tubsrobustcheck/corruptions_hu35adbfae16189e3e7129a7ebe2250739_527923_f04257b5bf6b0845e88aff0ae3ff9586.webp 760w,
               /project/tubsrobustcheck/corruptions_hu35adbfae16189e3e7129a7ebe2250739_527923_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://edgmin.github.io/project/tubsrobustcheck/corruptions_hu35adbfae16189e3e7129a7ebe2250739_527923_869b30c362c544b6b1e78139973c81b1.webp&#34;
               width=&#34;760&#34;
               height=&#34;294&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The idea is that we corrupt images by adding some artifact to them. In turn, these artifacts try to depict real-world scenarios. For instance, the frost weather corruption tries to depict the case where there is frost covering the camera lens. Similarly, the motion blur tries to depict the case where some motion affects the image capture process, etc.&lt;/p&gt;
&lt;h2 id=&#34;final-remarks&#34;&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TUBSRobustCheck&lt;/a&gt; is a PyTorch-based, architecture-agnostic toolbox that tries to address diverse challenging scenarios that semantic segmentation autonomous systems may face in the wild. It contains the most common benchmarks to evaluate the robustness of semantic segmentation neural networks against diverse attacks and corruptions.&lt;/p&gt;
&lt;p&gt;I hope this project presentation could show you the importance of investigating the robustness of semantic segmentation neural networks.  Please ping me a message in case one any doubts and have a good experience using the &lt;a href=&#34;https://github.com/ifnspaml/TUBSRobustCheck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TUBSRobustCheck&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Feel free to share our toolbox using the links below ðŸ˜ƒ&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://edgmin.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://edgmin.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>https://edgmin.github.io/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://edgmin.github.io/privacy/</guid>
      <description>&lt;p&gt;Add your privacy policy here and set &lt;code&gt;draft: false&lt;/code&gt; to publish it. Otherwise, delete this file if you don&amp;rsquo;t need it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://edgmin.github.io/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://edgmin.github.io/terms/</guid>
      <description>&lt;p&gt;Add your terms here and set &lt;code&gt;draft: false&lt;/code&gt; to publish it. Otherwise, delete this file if you don&amp;rsquo;t need it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://edgmin.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://edgmin.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
