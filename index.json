[{"authors":null,"categories":null,"content":"Hi there! Welcome to my personal page üòÉ.\nI am a last year master‚Äôs student in Computational Sciences in Engineering at the Technical University of Braunschweig. My research interests lie in 3D scene understanding and path planning for autonomous vehicles by combining data from multiple sources. I am also particularly interested in endowing deep learning algorithms with strong learning biases to make them more data-efficient. You can find my CV here.\n","date":1658016000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1658016000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi there! Welcome to my personal page üòÉ.\nI am a last year master‚Äôs student in Computational Sciences in Engineering at the Technical University of Braunschweig. My research interests lie in 3D scene understanding and path planning for autonomous vehicles by combining data from multiple sources.","tags":null,"title":"Edgard Minete","type":"authors"},{"authors":["Edgard Minete"],"categories":null,"content":"In this post, I would like to talk a bit about the work I developed during my master‚Äôs thesis at the Computer Vision \u0026amp; Artificial Intelligence Group of the Technical University of Munich, under the supervision of Dr. Vladimir Golkov.\nTo begin with, I believe it is worth explaining how I ended up writing my master‚Äôs thesis at TU Munich, since I was pursuing my studies at TU Braunschweig.\nWhen I was planning/looking for a master‚Äôs thesis topic, I could not really find anything that got my attention at TU Braunschweig. Then, I decided to look around and, after a few days and emails, I was fortunate to get to know Dr. Golkov from TU Munich. As I planned to learn the behind the scenes of deep learning, before accepting to write my master‚Äôs thesis at TU Munich I asked Vladimir about the potential topics I could work on. He offered me a range of topics, but one of them really stood out in the crowd: understanding deep learning. That was instantly a match for me, as I was definitely searching for something to comprehensively understand deep learning and its concepts.\nAfter a year reading hundreds of papers, having tons of fruitful discussions, and constantly coding, I successfully presented my master‚Äôs thesis at TU Braunschweig. Though still an ongoing work, below I present a draft of it with some discussion for those who might be interested. An article on arXiv will also appear soon üòÑ.\nData-efficiency in deep learning Deep learning-based methods rely on many strategies to achieve data-efficiency. One of the most common techniques is to endow models with prior knowledge about the underlying problem by using neural network layers with purposefully tailored properties. This approach lies at the heart of deep learning, but is quite often overlooked by machine learning practitioners.\nLet‚Äôs take a look at the prominent example of convolutional neural networks (CNNs).\nCNNs are empowered with convolutional and pooling layers, which leverage them with translation equivariance and scale separation capabilities (not to mention the deep natural image initialization prior - but that‚Äôs worth another post).\nThese aspects of CNNs are essentially what make them shine, as they substantially reduce the number of parameters, the associated computational cost, and the amount of data needed for training. Interestingly (and perhaps unnoticed by many), at a more macroscopic level, certain architectural design and training strategies are also known to greatly benefit neural networks‚Äô performance. These strategies can be very diverse and range from a simple cluster assumption to more complex concepts such as adversarial learning. However, there is one interesting difference. Namely, there is evidence that the latter strategies pose a more abstract power, being transferable across different data types and tasks. The problem is that there are neither guidelines about when using such strategies is beneficial, nor clear explanations about how they help to solve issues in deep learning approaches.\nDeep Domain Adaptation: Taxonomy and New Methods In my master‚Äôs thesis, I researched about design strategies (patterns) and tried to understand the context in which they are employed and what problems they try to solve. In other words, I investigated task- and data-agnostic architectural design patterns for recurring problems in deep learning.\nFor the analysis, I used an existing ‚Äúvisual language‚Äù of the Computer Vision \u0026amp; Artificial Intelligence Group. The idea behind this visual language is to abstract out neural networks‚Äô topological details, such as type and number of layers, and therefore to provide a common language to analyze deep learning methods. By bringing diverse methods under the same umbrella, I could identify more than 20 design patterns employed throughout deep learning. Furthermore, to understand the machine learning scenario in which each design pattern is commonly employed, I proposed an ontology of machine learning tasks. Combining the list of design patterns and the ontology of machine learning tasks, a methodology for a more structured design of novel deep learning approaches was possible.\nAs a proof of concept of the proposed methodology, I extended an existing unsupervised (self-supervised contrastive) deep domain adaptation approach by injecting design patterns into it. Interestingly, the changes leveraged state-of-the-art performance on the popular and challenging VisDA-2017 domain adaptation benchmark, providing empirical evidence that design patterns are interchangeable across distinct machine learning tasks and data types.\nFor now, I am still working on this topic and doing additional experiments. Nonetheless, I am confident that the proposed methodology will be the starting point of a more structured analysis of deep learning approaches, and that it will provide guidelines for the design of novel deep learning approaches.\nA paper about it is expected to be released soon. So, be tuned!\n","date":1658016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658016000,"objectID":"0861f70ab11fb2a9980958066dee4b86","permalink":"https://edgmin.github.io/post/masters/","publishdate":"2022-07-17T00:00:00Z","relpermalink":"/post/masters/","section":"post","summary":"An overview of my master's thesis project","tags":["Master Thesis","Deep Learning","Domain Adaptation","Self-supervised Learning","Unsupervised Learning","Contrastive methods"],"title":"Deep Domain Adaptation - Taxonomy and New Methods","type":"post"},{"authors":["Edgard Minete"],"categories":null,"content":"As this is the first post of my personal blog, it couldn‚Äôt be different: today I will write a bit about my academic and professional journey!\nI began my studies back in 2009, when I started a technical course in mechanics at the Federal Institute of Esp√≠rito Santo, Brazil. In this course, I was exposed to a range of topics including mechanical projects, electronics, mechanical fabrication, metrology, materials science and beyond. The course was half-half theory and practice. Thereby, I also acquired some hands-on experience. Further, I had the opportunity to lead the welding lab practices for a cohort of about 20 students during one semester.\nIn 2010, I was fortunate to be admitted to the main university of my state, UFES, in the undergraduate course of Mechanical Engineering. Simultaneously, I started to learn the English and German languages, as I was planning to one day study abroad.\nIn 2011, the Brazilian government launched the Science Without Boarders - CSF exchange program, which gave the opportunity to outstanding students to have experiences abroad by providing them with scholarships. As I was already learning foreign languages and had good grades in my undergraduate studies, I could meet the admission requirements and I was offered a scholarship to study in Germany.\nIn 2013, I moved to Dresden, Germany, to then start my exchange program. There, I lived for 3 months and participated in intensive German culture and language courses. After this adaptation period, I moved to the city of Zwickau, where I participated in the Automotive Engineering and Management course as an exchange master student. During the course, I had the opportunity to gain general knowledge about the automotive industry, such as motor development, acoustics, logistics and beyond. Importantly, I also had my first experiences with simulation sciences (in particular computational fluid dynamics), which rapidly increased my interest in the field. Besides that, I did an internship at Audi AG on the resistance welding development team between 2014 and 2015. There, I learned more about the German labor market, vividly experienced the German culture, and gained knowledge of robotic welding.\nAfter the internship at Audi AG, I moved back to Brazil to finish my undergraduate studies in Mechanical Engineering. Simultaneously, I did an internship in a local company (Tecvix), where I was responsible for performing mechanical and fluid dynamics simulations for diverse projects in the oil and gas industry. These simulation experiences, together with the similar experiences I had in Germany, directly influenced my decision to further expand my knowledge in the direction of computational sciences.\nAfter concluding the undergraduate course in Mechanical Engineering in the middle of 2017, I was fortunate to be admitted to the master in Computational Sciences in Engineering at the Technical University of Braunschweig. During my masters‚Äô studies, I chose the specialization in Mathematics and Computer Science, but I also took diverse lectures in fluid dynamics. Simultaneously with the theoretical lectures, I sought to improve my research abilities. Therefore, I worked as a research assistant in two different research institutes for more than 2 years.\nAt the Institute for Communications Technology, I worked on projects related to the robustness of semantic segmentation deep neural networks (DNNs) under the supervision of Andreas B√§r. Among others, the tasks I contributed include: improving an existing approach for domain mismatch estimation by means of multi-task learning and autoencoders; implementing a teacher-student framework for semantic segmentation; and implementing a PyTorch-based toolbox to assess the robustness of semantic segmentation DNNs against diverse adversarial attacks and corruptions.\nAt the same time, I also worked as a research assistant at the Institute of Joining and Welding. There, I had further hands-on experience in simulation sciences and machine learning by working on diverse weld-related projects. My activities there included: development of a differential geometry-based tool to assess porosity properties in welded specimens using 3D computed tomography data; implementation of a ResNet-based data-efficient neural network for the prediction of stress-strain curve of welded alloys using multi-fidelity (2D/3D simulation and experimental) depth-indentation testing data; execution of multi-focal laser welding thermal simulations for welding parameter estimation; and developed a weld bead image segmentation tool to automatically segment and measure weld beads.\nIn 2020, I wrote my masters thesis at the Technical University of Munich where I was supervised by Vladimir Golkov and worked on topics around understanding of deep learning, self-supervised learning, and unsupervised deep domain adaptation. If you are interested in reading more about my master‚Äôs thesis, please take a look at this post.\nTo conclude, I would like to share my ‚Ä¶","date":1657756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657843200,"objectID":"e2a6f040cec8e74565d35e1a65ca48e5","permalink":"https://edgmin.github.io/post/journey/","publishdate":"2022-07-14T00:00:00Z","relpermalink":"/post/journey/","section":"post","summary":"Some words about my academic and professional background","tags":["CV"],"title":"A Multidisciplinary Journey","type":"post"},{"authors":null,"categories":null,"content":"Autonomous vehicles need to understand the world around them in order to safely navigate in our complex and highly dynamic city environments. Towards that objective, diverse deep learning approaches have been rather successful. However, recent studies have shown that neural networks can be easily fooled by careful modification of the input image, raising serious concerns about the real robustness of such systems.\nDuring the last two years, I have worked as a research assistant under the supervision of Andreas B√§r at the Signal Processing and Machine Learning Group of the Technische Universit√§t Braunschweig. During this time, I worked on diverse topics around the robustness of neural networks. Today, I am very happy to share one of the main results of my work, the TUBSRobustCheck toolbox! TUBSRobustCheck is a PyTorch-based, architecture-agnostic toolbox developed to enable researchers to assess the robustness of their semantic segmentation neural networks against diverse attacks and corruptions.\nOur proposed toolbox is divided into two blocks: attacks, which contains various individual and universal adversarial attacks, and corruptions, which implements common image corruptions, as first introduced by Hendrycks et al, 2019.\nLets now dive deep into some capabilities of our toolbox!\nThe TUBSRobustCheck Attack toolbox Among others, our toolbox implements the Fast Gradient Sign Method (FGSM) (and its iterative and momentum variants), Generalizable Data-free Universal Adversarial Perturbations (GD-UAP), and the Metzen single image and universal attacks. Below, I show examples that were produced with our toolbox using a SwiftNet as a semantic segmentation neural network.\nThe top left image shows the original image that a neural network generally receives as input. Without any corruption, a state-of-the-art semantic segmentation neural network will produce a segmentation prediction that resembles the clean prediction at the bottom row left. Note that this prediction is very similar to the actual groundtruth image depicted at the bottom row right.\nBy applying some attack to it, in this case the Metzen single static image, an adversarial perturbation is computed (top row right). This adversarial perturbation can be added to the original input image to form an adversarial example (top row middle), which still looks like a clean image to humans. However, by feeding the perturbed image to the semantic segmentation network, we observe that the network predicts a scene with distinct semantics, showing the vulnerability of the semantic segmentation network.\nThis attack was purposefully designed to fool the neural network into predicting a static scene. In addition to that, our toolbox also contemplates other types of attacks, such as the dynamic Metzen:\nIn this case, instead of fooling the network to produce some pre-defined (static) image, we fool it into misclassifying some target semantic class of the input image. In this case, we produced a targeted adversarial perturbation to fool the neural network into wrongly classifying pixels of pedestrians. (Stop here for a moment and imagine how dangerous it would be to have a system failing/being attacked in this way!)\nThe TUBSRobustCheck Corruption toolbox Apart from adversarial attacks, our toolbox also implements diverse corruptions. For that, we followed the work of Hendrycks et al, 2019 and implemented corruptions of four classes: Noise (Gaussian, shot, impulse, and speckle), Blur (defocus, glass, motion, zoom, and Gaussian), Weather (snow, Frost, fog, brightness, and spatter), and Digital (contrast, elastic transform, pixelate, JPEG compression, and saturate). With these classes, we hope to cover some of the most common types of image corruption.\nTo illustrate the capabilities of our corruption toolbox, below we have some examples:\nThe idea is that we corrupt images by adding some artifact to them. In turn, these artifacts try to depict real-world scenarios. For instance, the frost weather corruption tries to depict the case where there is frost covering the camera lens. Similarly, the motion blur tries to depict the case where some motion affects the image capture process, etc.\nFinal remarks The TUBSRobustCheck is a PyTorch-based, architecture-agnostic toolbox that tries to address diverse challenging scenarios that autonomous systems for semantic segmentation may face in the wild. It contains the most common benchmarks to evaluate the robustness of semantic segmentation neural networks against diverse attacks and corruptions.\nI hope this project presentation could show you the importance of investigating the robustness of semantic segmentation neural networks. Please ping me a message in case one any doubts and have a good experience using the TUBSRobustCheck!\nFeel free to share our toolbox using the links below üòÉ\n","date":1657670400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657670400,"objectID":"0ab882ee4d918117ec78a8dbc41143d2","permalink":"https://edgmin.github.io/project/tubsrobustcheck/","publishdate":"2022-07-13T00:00:00Z","relpermalink":"/project/tubsrobustcheck/","section":"project","summary":"A PyTorch-based toolbox to evaluate the robustness of semantic segmentation deep neural networks against diverse corruptions and adversarial attacks.","tags":["Scene Understanding","Adversarial Attacks","Robustness","Deep Learning"],"title":"TUBSRobustCheck - assessing the robustness of semantic segmentation neural networks","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://edgmin.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]