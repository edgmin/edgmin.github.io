[{"authors":null,"categories":null,"content":"Hi there! Welcome to my personal page.\nI am a last year master student on Computational Sciences in Engineering at the Technical University of Braunschweig. My research interests lie in 3D scene reconstruction and its semantic understanding by combining SLAM and deep learning methods. Further, I am interested in endowing deep learning algorithms with strong learning biases to give them the ability of infering physics of the world.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi there! Welcome to my personal page.\nI am a last year master student on Computational Sciences in Engineering at the Technical University of Braunschweig. My research interests lie in 3D scene reconstruction and its semantic understanding by combining SLAM and deep learning methods.","tags":null,"title":"Edgard Minete","type":"authors"},{"authors":null,"categories":null,"content":"Autonomous vehicles need to understand the world around them in order to safely navigate in our complex and highly dynamic city environments. Towards that objective, diverse deep learning approaches have been proposed and were rather successful. However, recent studies have shown that neural networks can be easily fooled by careful modification of the input image, raising serious concerns about the real robustness of such systems.\nDuring the last two years, I have worked as a research assistant under the supervision of Andreas Bär at the Signal Processing and Machine Learning Group of the Technische Universität Braunschweig. During this time, I worked on diverse topics around the robustness of neural networks. Today, I am very happy to share one of the main results of my work, the TUBSRobustCheck toolbox! TUBSRobustCheck is a PyTorch-based, architecture-agnostic toolbox developed to enable researchers to assess the robustness of their semantic segmentation neural networks against diverse attacks and corruptions.\nOur proposed toolbox is divided into two blocks: attacks, which contains various individual and universal adversarial attacks, and corruptions, which implements common image corruptions, as first introduced by Hendrycks et al, 2019.\nLets now dive into some capabilities of our toolbox!\nAmong others, our toolbox implements the Fast Gradient Sign Method (FGSM) (and its iterative and momentum variants), Generalizable Data-free Universal Adversarial Perturbations (GD-UAP), and the Metzen single image and universal attacks. Below, I show examples that were produced with out toolbox using a SwiftNet as a semantic segmentation neural network.\nThe top left image shows the original image that a neural network generally receives as input. Without any corruption, a state-of-the-art semantic segmentation neural network will produce a segmentation prediction that resembles the clean prediction on the bottom row left. Note that this prediction is very similar to the actual groundtruth image depicted at the bottom row right.\nBy applying some attack to it, in this case the Metzen single static image, an adversarial perturbation is computed (top row right). This adversarial perturbation can be added to the original input image to form an adversarial example (top row middle), which still looks like a clean image to humans. However, by feeding the perturbed image to the semantic segmentation network, we observe that the network predicts a scene with distinct semantics, showing the vulnerability of the semantic segmentation network.\nThis attack was purposefully designed to fool the neural network into predicting a static scene. In addition to that, our toolbox also contemplates other tips of attacks, such as the dynamic Metzen:\nIn this case, instead of fooling the network to produce a some pre-defined (static) image, we fool it into misclassifying some target semantic class of the input image. In this case, we produced a targeted adversarial perturbation to fool the neural network into wrongly classifying pixels of pedestrians. (Stop for a moment and imagine how dangerous would be to have such a system failing/being attacked in this way!)\nApart from adversarial attacks, our toolbox also implements diverse corruptions. For that, we followed the work of Hendrycks et al, 2019 and implemented corruptions of four classes: Noise (Gaussian, shot, impulse, and speckle), Blur (defocus, glass, motion, zoom, and Gaussian), Weather (snow, Frost, fog, brightness, and spatter), and Digital (contrast, elastic transform, pixelate, JPEG compression, and saturate). With these classes, we hope to cover some of the most common types of image corruptions.\nTo illustrate the capabilities of our corruption toolbox, below we have some examples:\nThe idea is that we corrupt images by adding some artifact to them. In turn, these artifacts try to depict real-world scenarios. For instance, the frost weather corruption tries to depict the case where there is frost covering the camera lens. Similarly, the motion blur tries to depict the case where some motion affects the image capture process, etc.\nIn summary: the TUBSRobustCheck is a PyTorch-based, architecture-agnostic toolbox that tries to address diverse challenging scenarios that autonomous systems for semantic segmentation may face in the wild. It contains the most common benchmarks to evaluate the robustness of semantic segmentation neural networks against diverse attacks and corruptions.\nI hope this project presentation could show you the importance of investigating the robustness of semantic segmentation neural networks. Please ping me a message in case one any doubts and have a good experience using the TUBSRobustCheck!\n","date":1657756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657756800,"objectID":"0ab882ee4d918117ec78a8dbc41143d2","permalink":"https://edgmin.github.io/project/tubsrobustcheck/","publishdate":"2022-07-14T00:00:00Z","relpermalink":"/project/tubsrobustcheck/","section":"project","summary":"A PyTorch-based toolbox to evaluate the robustness of semantic segmentation deep neural networks.","tags":["Semantic Segmentation","Adversarial Attacks","Robustness","Deep Learning"],"title":"TUBSRobustCheck","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://edgmin.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]